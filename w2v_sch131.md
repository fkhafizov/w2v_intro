# Введение в векторное представление слов.

В лекции на простом примере показано, как работает алгоритм skip-gram, распознающий контекстное распределение слов [2].  Для понимания алгоритма достаточно  школьной математики и понятия градиента (с которым старшеклассников можно ознакомить на 1-2 факультативных занятиях). Из-за ограничения во времени за рамками обсуждения остались negative sampling и некоторые эвристики алгоритма skip-gram [2].

<!--- just --->

* [видео.](https://youtu.be/8BHJCK2-2ek) Нажмите **SHOW MORE**, чтобы перейти к нужному разделу видео
* [слайды (slides)](https://github.com/fkhafizov/w2v_intro/blob/main/w2v_sch131_2021.10.15.pdf)
* [код на Колабе (python code on Colab)](https://github.com/fkhafizov/w2v_intro/blob/main/w2v_sch131_2021_10_15.ipynb)

Статьи Миколова:<br>
 [1] [Mikolov et al 2013.09](https://arxiv.org/pdf/1301.3781.pdf)<br>
 [2] [Mikolov et al 2013.10](https://arxiv.org/pdf/1310.4546.pdf)
